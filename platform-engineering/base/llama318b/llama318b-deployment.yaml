apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama318b
  namespace: sasya-chikitsa
  labels:
    app: llama318b
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama318b
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  progressDeadlineSeconds: 600
  template:
    metadata:
      labels:
        app: llama318b
    spec:
      containers:
        - name: ollama318b
          image: quay.io/rajivranjan/ollama-model-llama318b-amd64:v1
          imagePullPolicy: Always
          ports:
            - containerPort: 11434
              protocol: TCP
          resources:
            requests:
              memory: "10Gi"
              cpu: "2"
            limits:
              memory: "12Gi"
              cpu: "4"
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          livenessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 30
            periodSeconds: 10
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
            fsGroup: 1000
          env:
            - name: OLLAMA_ROOT
              value: /ollama-data
            - name: OLLAMA_HOST
              value: 0.0.0.0:11434
            - name: HOME
              value: /ollama-data
          volumeMounts:
            - name: ollama-data-volume
              mountPath: /ollama-data
      volumes:
        - name: ollama-data-volume
          persistentVolumeClaim:
            claimName: ollama-data-pvc
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      terminationGracePeriodSeconds: 30